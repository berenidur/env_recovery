{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWindow():\n",
    "    def __init__(self, comp_env_window, R, S, beta, k, validRS, a_0):\n",
    "        self.comp_env_window = comp_env_window\n",
    "        self.R = R\n",
    "        self.S = S\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        self.validRS = validRS\n",
    "        self.a_0 = a_0\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"comp_env_window: {self.comp_env_window}\\nR: {self.R}\\nS: {self.S}\\nbeta: {self.beta}\\nk: {self.k}\\nvalidRS: {self.validRS}\\na_0: {self.a_0}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_sizes(h5_path):\n",
    "    with h5py.File(h5_path, 'r') as file:\n",
    "        for group in file.keys():\n",
    "            dataset_name = f'{group}/comp_env_interp_1'\n",
    "            if dataset_name in file:\n",
    "                data = np.array(file[dataset_name])\n",
    "                print(f'Size of dataset {dataset_name}: {data.shape}')\n",
    "            else:\n",
    "                print(f'Dataset {dataset_name} not found')\n",
    "\n",
    "def print_first_group_datasets(h5_path):\n",
    "    with h5py.File(h5_path, 'r') as file:\n",
    "        first_group = list(file.keys())[0]\n",
    "        print(f\"Datasets in the first group ({first_group}):\")\n",
    "        for dataset in file[first_group].keys():\n",
    "            data = np.array(file[first_group][dataset])\n",
    "            print(f\" - {dataset}: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in the first group (file_0001):\n",
      " - R_matrix: (188, 200)\n",
      " - S_matrix: (188, 200)\n",
      " - a_0: (1, 1)\n",
      " - b_0: (1, 1)\n",
      " - beta_matrix: (188, 200)\n",
      " - comp_env_interp_1: (244, 256)\n",
      " - env_rf_interp: (244, 256)\n",
      " - k_matrix: (188, 200)\n",
      " - n: (1, 1)\n",
      " - validRS: (188, 200)\n"
     ]
    }
   ],
   "source": [
    "h5_path = '../data/dataoncosalud/res_valid/breast_comp_env_data.h5'\n",
    "# print_dataset_sizes(h5_path)\n",
    "print_first_group_datasets(h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of 57x57 windows: 22988144\n",
      "comp_env_window: [[137.75766683 133.2111603  141.7927883  ... 177.76114717 176.87902033\n",
      "  173.15100083]\n",
      " [164.15741549 167.85168201 171.77379703 ... 171.75821628 162.46338627\n",
      "  154.54537015]\n",
      " [153.70165877 163.45111897 165.52004356 ... 150.50108707 154.16908375\n",
      "  162.24663787]\n",
      " ...\n",
      " [153.71254841 165.316187   157.39771172 ... 155.60340152 165.28534673\n",
      "  152.62939152]\n",
      " [155.92038459 161.35482999 157.31458726 ... 147.1035658  156.74833358\n",
      "  146.60485593]\n",
      " [160.48098243 166.74628761 160.25674777 ... 161.06037448 162.99252765\n",
      "  159.6153866 ]]\n",
      "R: 1.8394473726407958\n",
      "S: 1.445157404233818\n",
      "beta: 0.38330175426580004\n",
      "k: 3.3610563904074784\n",
      "validRS: 0.0\n",
      "a_0: 22.4888433408961\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_windows(h5_path, n):\n",
    "    total_windows = 0\n",
    "    with h5py.File(h5_path, 'r') as file:\n",
    "        for group in file.keys():\n",
    "            dataset_name = f'{group}/comp_env_interp_1'\n",
    "            if dataset_name in file:\n",
    "                data = np.array(file[dataset_name])\n",
    "                if data.ndim == 2:\n",
    "                    num_windows = ((data.shape[0] - n + 1) * (data.shape[1] - n + 1))\n",
    "                    total_windows += num_windows\n",
    "                else:\n",
    "                    raise ValueError(f\"Dataset {dataset_name} is not 2-dimensional\")\n",
    "            else:\n",
    "                raise ValueError(f\"Dataset {dataset_name} not found\")\n",
    "    return total_windows\n",
    "\n",
    "# def get_window_xy(h5_path, n, window_idx):\n",
    "#     total_windows = calculate_total_windows(h5_path, n)\n",
    "#     if window_idx >= total_windows:\n",
    "#         raise IndexError(\"Window index out of range\")\n",
    "    \n",
    "#     current_window = 0\n",
    "#     with h5py.File(h5_path, 'r') as file:\n",
    "#         for group in file.keys():\n",
    "#             dataset_name = f'{group}/comp_env_interp_1'\n",
    "#             validRS_name = f'{group}/validRS'\n",
    "#             if dataset_name in file and validRS_name in file:\n",
    "#                 data = np.array(file[dataset_name])\n",
    "#                 if data.ndim == 2:\n",
    "#                     num_windows = ((data.shape[0] - n + 1) * (data.shape[1] - n + 1))\n",
    "#                     if current_window + num_windows > window_idx:\n",
    "#                         local_idx = window_idx - current_window\n",
    "#                         row_idx = local_idx // (data.shape[1] - n + 1)\n",
    "#                         col_idx = local_idx % (data.shape[1] - n + 1)\n",
    "#                         comp_env_window = data[row_idx:row_idx+n, col_idx:col_idx+n]\n",
    "\n",
    "#                         validRS = np.array(file[validRS_name])\n",
    "#                         validRS_value = validRS[row_idx, col_idx]\n",
    "\n",
    "#                         return comp_env_window, validRS_value\n",
    "#                     current_window += num_windows\n",
    "#                 else:\n",
    "#                     raise ValueError(f\"Dataset {dataset_name} is not 2-dimensional\")\n",
    "#             else:\n",
    "#                 raise ValueError(f\"Dataset {dataset_name} or {validRS_name} not found\")\n",
    "#     raise IndexError(\"Window index out of range\")\n",
    "\n",
    "def get_window_xy(h5_path, n, window_idx):\n",
    "    total_windows = calculate_total_windows(h5_path, n)\n",
    "    if window_idx >= total_windows:\n",
    "        raise IndexError(\"Window index out of range\")\n",
    "    \n",
    "    current_window = 0\n",
    "    with h5py.File(h5_path, 'r') as file:\n",
    "        for group in file.keys():\n",
    "            dataset_name = f'{group}/comp_env_interp_1'\n",
    "            R_matrix_name = f'{group}/R_matrix'\n",
    "            S_matrix_name = f'{group}/S_matrix'\n",
    "            a_0_name = f'{group}/a_0'\n",
    "            beta_matrix_name = f'{group}/beta_matrix'\n",
    "            k_matrix_name = f'{group}/k_matrix'\n",
    "            validRS_name = f'{group}/validRS'\n",
    "            if dataset_name in file and validRS_name in file:\n",
    "                data = np.array(file[dataset_name])\n",
    "                if data.ndim == 2:\n",
    "                    num_windows = ((data.shape[0] - n + 1) * (data.shape[1] - n + 1))\n",
    "                    if current_window + num_windows > window_idx:\n",
    "                        local_idx = window_idx - current_window\n",
    "                        row_idx = local_idx // (data.shape[1] - n + 1)\n",
    "                        col_idx = local_idx % (data.shape[1] - n + 1)\n",
    "                        comp_env_window = data[row_idx:row_idx+n, col_idx:col_idx+n]\n",
    "\n",
    "                        R = np.array(file[R_matrix_name])\n",
    "                        R_value = R[row_idx, col_idx]\n",
    "\n",
    "                        S = np.array(file[S_matrix_name])\n",
    "                        S_value = S[row_idx, col_idx]\n",
    "\n",
    "                        beta = np.array(file[beta_matrix_name])\n",
    "                        beta_value = beta[row_idx, col_idx]\n",
    "\n",
    "                        k = np.array(file[k_matrix_name])\n",
    "                        k_value = k[row_idx, col_idx]\n",
    "\n",
    "                        a_0 = np.array(file[a_0_name])\n",
    "                        a_value = a_0[0][0]\n",
    "\n",
    "                        validRS = np.array(file[validRS_name])\n",
    "                        validRS_value = validRS[row_idx, col_idx]\n",
    "\n",
    "                        return DataWindow(comp_env_window, R_value, S_value, beta_value, k_value, validRS_value, a_value)\n",
    "                    current_window += num_windows\n",
    "                else:\n",
    "                    raise ValueError(f\"Dataset {dataset_name} is not 2-dimensional\")\n",
    "            else:\n",
    "                raise ValueError(f\"Dataset {dataset_name} or {validRS_name} not found\")\n",
    "    raise IndexError(\"Window index out of range\")\n",
    "\n",
    "# Example usage\n",
    "n=57\n",
    "total_windows = calculate_total_windows(h5_path, n)\n",
    "print(f'Total number of {n}x{n} windows: {total_windows}')\n",
    "\n",
    "window_idx = 8964152\n",
    "comp_env_window = get_window_xy(h5_path, n, window_idx)\n",
    "print(comp_env_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_0001/451\n",
      "file_0002/451\n",
      "file_0003/451\n",
      "file_0004/451\n",
      "file_0005/451\n",
      "file_0006/451\n",
      "file_0007/451\n",
      "file_0008/451\n",
      "file_0009/451\n",
      "file_0010/451\n",
      "file_0011/451\n",
      "file_0012/451\n",
      "file_0013/451\n",
      "file_0014/451\n",
      "file_0015/451\n",
      "file_0016/451\n",
      "file_0017/451\n",
      "file_0018/451\n",
      "file_0019/451\n",
      "file_0020/451\n",
      "file_0021/451\n",
      "file_0022/451\n",
      "file_0023/451\n",
      "file_0024/451\n",
      "file_0025/451\n",
      "file_0026/451\n",
      "file_0027/451\n",
      "file_0028/451\n",
      "file_0029/451\n",
      "file_0030/451\n",
      "file_0031/451\n",
      "file_0032/451\n",
      "file_0033/451\n",
      "file_0034/451\n",
      "file_0035/451\n",
      "file_0036/451\n",
      "file_0037/451\n",
      "file_0038/451\n",
      "file_0039/451\n",
      "file_0040/451\n",
      "file_0041/451\n",
      "file_0042/451\n",
      "file_0043/451\n",
      "file_0044/451\n",
      "file_0045/451\n",
      "file_0046/451\n",
      "file_0047/451\n",
      "file_0048/451\n",
      "file_0049/451\n",
      "file_0050/451\n",
      "file_0051/451\n",
      "file_0052/451\n",
      "file_0053/451\n",
      "file_0054/451\n",
      "file_0055/451\n",
      "file_0056/451\n",
      "file_0057/451\n",
      "file_0058/451\n",
      "file_0059/451\n",
      "file_0060/451\n",
      "file_0061/451\n",
      "file_0062/451\n",
      "file_0063/451\n",
      "file_0064/451\n",
      "file_0065/451\n",
      "file_0066/451\n",
      "file_0067/451\n",
      "file_0068/451\n",
      "file_0069/451\n",
      "file_0070/451\n",
      "file_0071/451\n",
      "file_0072/451\n",
      "file_0073/451\n",
      "file_0074/451\n",
      "file_0075/451\n",
      "file_0076/451\n",
      "file_0077/451\n",
      "file_0078/451\n",
      "file_0079/451\n",
      "file_0080/451\n",
      "file_0081/451\n",
      "file_0082/451\n",
      "file_0083/451\n",
      "file_0084/451\n",
      "file_0085/451\n",
      "file_0086/451\n",
      "file_0087/451\n",
      "file_0088/451\n",
      "file_0089/451\n",
      "file_0090/451\n",
      "file_0091/451\n",
      "file_0092/451\n",
      "file_0093/451\n",
      "file_0094/451\n",
      "file_0095/451\n",
      "file_0096/451\n",
      "file_0097/451\n",
      "file_0098/451\n",
      "file_0099/451\n",
      "file_0100/451\n",
      "file_0101/451\n",
      "file_0102/451\n",
      "file_0103/451\n",
      "file_0104/451\n",
      "file_0105/451\n",
      "file_0106/451\n",
      "file_0107/451\n",
      "file_0108/451\n",
      "file_0109/451\n",
      "file_0110/451\n",
      "file_0111/451\n",
      "file_0112/451\n",
      "file_0113/451\n",
      "file_0114/451\n",
      "file_0115/451\n",
      "file_0116/451\n",
      "file_0117/451\n",
      "file_0118/451\n",
      "file_0119/451\n",
      "file_0120/451\n",
      "file_0121/451\n",
      "file_0122/451\n",
      "file_0123/451\n",
      "file_0124/451\n",
      "file_0125/451\n",
      "file_0126/451\n",
      "file_0127/451\n",
      "file_0128/451\n",
      "file_0129/451\n",
      "file_0130/451\n",
      "file_0131/451\n",
      "file_0132/451\n",
      "file_0133/451\n",
      "file_0134/451\n",
      "file_0135/451\n",
      "file_0136/451\n",
      "file_0137/451\n",
      "file_0138/451\n",
      "file_0139/451\n",
      "file_0140/451\n",
      "file_0141/451\n",
      "file_0142/451\n",
      "file_0143/451\n",
      "file_0144/451\n",
      "file_0145/451\n",
      "file_0146/451\n",
      "file_0147/451\n",
      "file_0148/451\n",
      "file_0149/451\n",
      "file_0150/451\n",
      "file_0151/451\n",
      "file_0152/451\n",
      "file_0153/451\n",
      "file_0154/451\n",
      "file_0155/451\n",
      "file_0156/451\n",
      "file_0157/451\n",
      "file_0158/451\n",
      "file_0159/451\n",
      "file_0160/451\n",
      "file_0161/451\n",
      "file_0162/451\n",
      "file_0163/451\n",
      "file_0164/451\n",
      "file_0165/451\n",
      "file_0166/451\n",
      "file_0167/451\n",
      "file_0168/451\n",
      "file_0169/451\n",
      "file_0170/451\n",
      "file_0171/451\n",
      "file_0172/451\n",
      "file_0173/451\n",
      "file_0174/451\n",
      "file_0175/451\n",
      "file_0176/451\n",
      "file_0177/451\n",
      "file_0178/451\n",
      "file_0179/451\n",
      "file_0180/451\n",
      "file_0181/451\n",
      "file_0182/451\n",
      "file_0183/451\n",
      "file_0184/451\n",
      "file_0185/451\n",
      "file_0186/451\n",
      "file_0187/451\n",
      "file_0188/451\n",
      "file_0189/451\n",
      "file_0190/451\n",
      "file_0191/451\n",
      "file_0192/451\n",
      "file_0193/451\n",
      "file_0194/451\n",
      "file_0195/451\n",
      "file_0196/451\n",
      "file_0197/451\n",
      "file_0198/451\n",
      "file_0199/451\n",
      "file_0200/451\n",
      "file_0201/451\n",
      "file_0202/451\n",
      "file_0203/451\n",
      "file_0204/451\n",
      "file_0205/451\n",
      "file_0206/451\n",
      "file_0207/451\n",
      "file_0208/451\n",
      "file_0209/451\n",
      "file_0210/451\n",
      "file_0211/451\n",
      "file_0212/451\n",
      "file_0213/451\n",
      "file_0214/451\n",
      "file_0215/451\n",
      "file_0216/451\n",
      "file_0217/451\n",
      "file_0218/451\n",
      "file_0219/451\n",
      "file_0220/451\n",
      "file_0221/451\n",
      "file_0222/451\n",
      "file_0223/451\n",
      "file_0224/451\n",
      "file_0225/451\n",
      "file_0226/451\n",
      "file_0227/451\n",
      "file_0228/451\n",
      "file_0229/451\n",
      "file_0230/451\n",
      "file_0231/451\n",
      "file_0232/451\n",
      "file_0233/451\n",
      "file_0234/451\n",
      "file_0235/451\n",
      "file_0236/451\n",
      "file_0237/451\n",
      "file_0238/451\n",
      "file_0239/451\n",
      "file_0240/451\n",
      "file_0241/451\n",
      "file_0242/451\n",
      "file_0243/451\n",
      "file_0244/451\n",
      "file_0245/451\n",
      "file_0246/451\n",
      "file_0247/451\n",
      "file_0248/451\n",
      "file_0249/451\n",
      "file_0250/451\n",
      "file_0251/451\n",
      "file_0252/451\n",
      "file_0253/451\n",
      "file_0254/451\n",
      "file_0255/451\n",
      "file_0256/451\n",
      "file_0257/451\n",
      "file_0258/451\n",
      "file_0259/451\n",
      "file_0260/451\n",
      "file_0261/451\n",
      "file_0262/451\n",
      "file_0263/451\n",
      "file_0264/451\n",
      "file_0265/451\n",
      "file_0266/451\n",
      "file_0267/451\n",
      "file_0268/451\n",
      "file_0269/451\n",
      "file_0270/451\n",
      "file_0271/451\n",
      "file_0272/451\n",
      "file_0273/451\n",
      "file_0274/451\n",
      "file_0275/451\n",
      "file_0276/451\n",
      "file_0277/451\n",
      "file_0278/451\n",
      "file_0279/451\n",
      "file_0280/451\n",
      "file_0281/451\n",
      "file_0282/451\n",
      "file_0283/451\n",
      "file_0284/451\n",
      "file_0285/451\n",
      "file_0286/451\n",
      "file_0287/451\n",
      "file_0288/451\n",
      "file_0289/451\n",
      "file_0290/451\n",
      "file_0291/451\n",
      "file_0292/451\n",
      "file_0293/451\n",
      "file_0294/451\n",
      "file_0295/451\n",
      "file_0296/451\n",
      "file_0297/451\n",
      "file_0298/451\n",
      "file_0299/451\n",
      "file_0300/451\n",
      "file_0301/451\n",
      "file_0302/451\n",
      "file_0303/451\n",
      "file_0304/451\n",
      "file_0305/451\n",
      "file_0306/451\n",
      "file_0307/451\n",
      "file_0308/451\n",
      "file_0309/451\n",
      "file_0310/451\n",
      "file_0311/451\n",
      "file_0312/451\n",
      "file_0313/451\n",
      "file_0314/451\n",
      "file_0315/451\n",
      "file_0316/451\n",
      "file_0317/451\n",
      "file_0318/451\n",
      "file_0319/451\n",
      "file_0320/451\n",
      "file_0321/451\n",
      "file_0322/451\n",
      "file_0323/451\n",
      "file_0324/451\n",
      "file_0325/451\n",
      "file_0326/451\n",
      "file_0327/451\n",
      "file_0328/451\n",
      "file_0329/451\n",
      "file_0330/451\n",
      "file_0331/451\n",
      "file_0332/451\n",
      "file_0333/451\n",
      "file_0334/451\n",
      "file_0335/451\n",
      "file_0336/451\n",
      "file_0337/451\n",
      "file_0338/451\n",
      "file_0339/451\n",
      "file_0340/451\n",
      "file_0341/451\n",
      "file_0342/451\n",
      "file_0343/451\n",
      "file_0344/451\n",
      "file_0345/451\n",
      "file_0346/451\n",
      "file_0347/451\n",
      "file_0348/451\n",
      "file_0349/451\n",
      "file_0350/451\n",
      "file_0351/451\n",
      "file_0352/451\n",
      "file_0353/451\n",
      "file_0354/451\n",
      "file_0355/451\n",
      "file_0356/451\n",
      "file_0357/451\n",
      "file_0358/451\n",
      "file_0359/451\n",
      "file_0360/451\n",
      "file_0361/451\n",
      "file_0362/451\n",
      "file_0363/451\n",
      "file_0364/451\n",
      "file_0365/451\n",
      "file_0366/451\n",
      "file_0367/451\n",
      "file_0368/451\n",
      "file_0369/451\n",
      "file_0370/451\n",
      "file_0371/451\n",
      "file_0372/451\n",
      "file_0373/451\n",
      "file_0374/451\n",
      "file_0375/451\n",
      "file_0376/451\n",
      "file_0377/451\n",
      "file_0378/451\n",
      "file_0379/451\n",
      "file_0380/451\n",
      "file_0381/451\n",
      "file_0382/451\n",
      "file_0383/451\n",
      "file_0384/451\n",
      "file_0385/451\n",
      "file_0386/451\n",
      "file_0387/451\n",
      "file_0388/451\n",
      "file_0389/451\n",
      "file_0390/451\n",
      "file_0391/451\n",
      "file_0392/451\n",
      "file_0393/451\n",
      "file_0394/451\n",
      "file_0395/451\n",
      "file_0396/451\n",
      "file_0397/451\n",
      "file_0398/451\n",
      "file_0399/451\n",
      "file_0400/451\n",
      "file_0401/451\n",
      "file_0402/451\n",
      "file_0403/451\n",
      "file_0404/451\n",
      "file_0405/451\n",
      "file_0406/451\n",
      "file_0407/451\n",
      "file_0408/451\n",
      "file_0409/451\n",
      "file_0410/451\n",
      "file_0411/451\n",
      "file_0412/451\n",
      "file_0413/451\n",
      "file_0414/451\n",
      "file_0415/451\n",
      "file_0416/451\n",
      "file_0417/451\n",
      "file_0418/451\n",
      "file_0419/451\n",
      "file_0420/451\n",
      "file_0421/451\n",
      "file_0422/451\n",
      "file_0423/451\n",
      "file_0424/451\n",
      "file_0425/451\n",
      "file_0426/451\n",
      "file_0427/451\n",
      "file_0428/451\n",
      "file_0429/451\n",
      "file_0430/451\n",
      "file_0431/451\n",
      "file_0432/451\n",
      "file_0433/451\n",
      "file_0434/451\n",
      "file_0435/451\n",
      "file_0436/451\n",
      "file_0437/451\n",
      "file_0438/451\n",
      "file_0439/451\n",
      "file_0440/451\n",
      "file_0441/451\n",
      "file_0442/451\n",
      "file_0443/451\n",
      "file_0444/451\n",
      "file_0445/451\n",
      "file_0446/451\n",
      "file_0447/451\n",
      "file_0448/451\n",
      "file_0449/451\n",
      "file_0450/451\n",
      "file_0451/451\n"
     ]
    }
   ],
   "source": [
    "def create_validRS_dataset(h5_path):\n",
    "    validRS_values = []\n",
    "    with h5py.File(h5_path, 'r') as file:\n",
    "        for group in file.keys():\n",
    "            print(f\"{group}/{len(file.keys())}\")\n",
    "            validRS_name = f'{group}/validRS'\n",
    "            if validRS_name in file:\n",
    "                validRS = np.array(file[validRS_name])\n",
    "                if validRS.ndim == 2:\n",
    "                    for row_idx in range(validRS.shape[0]):\n",
    "                        for col_idx in range(validRS.shape[1]):\n",
    "                            validRS_value = validRS[row_idx, col_idx]\n",
    "                            validRS_values.append(validRS_value)\n",
    "                else:\n",
    "                    raise ValueError(f\"Dataset {validRS_name} is not 2-dimensional\")\n",
    "            else:\n",
    "                raise ValueError(f\"Dataset {validRS_name} not found\")\n",
    "    validRS_values = np.array(validRS_values)\n",
    "    return validRS_values\n",
    "\n",
    "validRS_values=create_validRS_dataset(h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22988144,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validRS_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files: 698046, Validation files: 174468\n",
      "Training files: 838308, Validation files: 209280\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Get indices of 0s and 1s in validRS_values\n",
    "zero_indices = np.where(validRS_values == 0)[0]\n",
    "one_indices = np.where(validRS_values == 1)[0]\n",
    "\n",
    "# Calculate the number of 1s to be used in the dataset\n",
    "num_ones = len(one_indices)\n",
    "num_zeros = num_ones\n",
    "\n",
    "# Select an equal number of 0s\n",
    "selected_zero_indices, _ = train_test_split(zero_indices, train_size=num_zeros, random_state=42)\n",
    "\n",
    "# Combine the selected 0s and 1s\n",
    "selected_indices = np.concatenate((selected_zero_indices, one_indices))\n",
    "\n",
    "# Split the selected indices into training and validation sets\n",
    "train_indices, val_indices = train_test_split(selected_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure 50-50 ratio in both splits\n",
    "train_zeros = train_indices[validRS_values[train_indices] == 0]\n",
    "train_ones = train_indices[validRS_values[train_indices] == 1]\n",
    "val_zeros = val_indices[validRS_values[val_indices] == 0]\n",
    "val_ones = val_indices[validRS_values[val_indices] == 1]\n",
    "\n",
    "# Adjust the training set to have equal number of 0s and 1s\n",
    "if len(train_zeros) > len(train_ones):\n",
    "    train_zeros = train_zeros[:len(train_ones)]\n",
    "else:\n",
    "    train_ones = train_ones[:len(train_zeros)]\n",
    "\n",
    "# Adjust the validation set to have equal number of 0s and 1s\n",
    "if len(val_zeros) > len(val_ones):\n",
    "    val_zeros = val_zeros[:len(val_ones)]\n",
    "else:\n",
    "    val_ones = val_ones[:len(val_zeros)]\n",
    "\n",
    "# Combine adjusted indices\n",
    "train_indices = np.empty((train_zeros.size + train_ones.size,), dtype=train_zeros.dtype)\n",
    "train_indices[0::2] = train_zeros\n",
    "train_indices[1::2] = train_ones\n",
    "\n",
    "val_indices = np.empty((val_zeros.size + val_ones.size,), dtype=val_zeros.dtype)\n",
    "val_indices[0::2] = val_zeros\n",
    "val_indices[1::2] = val_ones\n",
    "\n",
    "# Save the splits into a pickle file\n",
    "split_data = {\n",
    "    'train_files': train_indices,\n",
    "    'val_files': val_indices\n",
    "}\n",
    "\n",
    "# with open('breast_data_splits_CNN.pkl', 'wb') as f:\n",
    "#     pickle.dump(split_data, f)\n",
    "\n",
    "print(f'Training files: {len(train_indices)}, Validation files: {len(val_indices)}')\n",
    "print('Training files: 838308, Validation files: 209280')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349023 349023 87234 87234\n",
      "349023.0 87234.0\n",
      "174511.0 43617.0\n"
     ]
    }
   ],
   "source": [
    "print(len(train_zeros), len(train_ones), len(val_zeros), len(val_ones))\n",
    "print(validRS_values[train_indices].sum(), validRS_values[val_indices].sum())\n",
    "print(validRS_values[train_indices[0:len(train_indices)//2]].sum(), validRS_values[val_indices[0:len(val_indices)//2]].sum())\n",
    "\n",
    "# print('419154 419154 104640 104640')\n",
    "# print('419154.0 104640.0')\n",
    "# print('209577.0 52320.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading windows: 100%|██████████| 3200/3200 [16:14<00:00,  3.29it/s]\n",
      "Loading windows: 100%|██████████| 800/800 [04:11<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train comp_env_windows shape: (3200,)\n",
      "Validation comp_env_windows shape: (800,)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def create_windows_array(h5_path, indices, n):\n",
    "    num_windows = len(indices)\n",
    "\n",
    "    windows = np.empty(num_windows, dtype=DataWindow)\n",
    "    \n",
    "    for i, idx in enumerate(tqdm(indices, desc=\"Loading windows\")):\n",
    "        windows[i] = get_window_xy(h5_path, n, idx)\n",
    "    \n",
    "    return windows\n",
    "\n",
    "# Create arrays for training and validation sets\n",
    "train_windows = create_windows_array(h5_path, train_indices[:3200], n)\n",
    "val_windows = create_windows_array(h5_path, val_indices[:800], n)\n",
    "\n",
    "print(f'Train comp_env_windows shape: {train_windows.shape}')\n",
    "print(f'Validation comp_env_windows shape: {val_windows.shape}')\n",
    "\n",
    "# Save the arrays into a pickle file\n",
    "data_arrays = {\n",
    "    'train_windows': train_windows,\n",
    "    'val_windows': val_windows\n",
    "}\n",
    "\n",
    "with open('breast_data_arrays_CNN.pkl', 'wb') as f:\n",
    "    pickle.dump(data_arrays, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coherenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
